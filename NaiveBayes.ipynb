{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from Eval import Eval\n",
    "from math import log, exp\n",
    "import time\n",
    "from imdb import IMDBdata\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eval:\n",
    "    def __init__(self, pred, gold):\n",
    "        self.pred = pred\n",
    "        self.gold = gold\n",
    "        #create a confusion matrix\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.tn = 0\n",
    "        self.fn = 0\n",
    "\n",
    "    def Accuracy(self):\n",
    "        return np.sum(np.equal(self.pred, self.gold)) / float(len(self.gold))\n",
    "\n",
    "    def Precision(self):\n",
    "        return self.tp / (self.tp + self.fp)\n",
    "\n",
    "    def Recall(self):\n",
    "        return self.tp / (self.tp + self.fn)\n",
    "\n",
    "    def ComputeConfusionMatrix(self):\n",
    "        for pred, label in zip(self.pred, self.gold):\n",
    "            if pred + label == 2:\n",
    "                self.tp += 1\n",
    "            elif(pred + label) == -2:\n",
    "                self.tn += 1\n",
    "            elif pred > label:\n",
    "                self.fp += 1\n",
    "            else:\n",
    "                self.fn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, data, ALPHA=1.0):\n",
    "        #Initialization of each instance variables by the type they need.\n",
    "        self.ALPHA = ALPHA\n",
    "        self.data = data\n",
    "        self.vocab_len = 0\n",
    "        self.num_positive_reviews = 0\n",
    "        self.num_negative_reviews = 0\n",
    "        self.total_number_of_reviews = 0\n",
    "        self.count_positive = defaultdict(int)\n",
    "        self.count_negative = defaultdict(int)\n",
    "        self.total_positive_words = 0\n",
    "        self.total_negative_words = 0\n",
    "        self.total_positive_term = 0\n",
    "        self.total_negative_term = 0\n",
    "        self.P_positive = defaultdict(float)\n",
    "        self.P_negative = defaultdict(float)\n",
    "        self.deno_pos = 0\n",
    "        self.deno_neg = 0\n",
    "\n",
    "        print(\"Training the model ...\")\n",
    "        self.Train(data.X,data.Y)\n",
    "\n",
    "    # Train model - X are instances, Y are labels (+1 or -1)\n",
    "    # X and Y are sparse matrices\n",
    "    def Train(self, X, Y):\n",
    "        #Estimation of the Naive Bayes model parameters\n",
    "\n",
    "        #Getting the number of unique word in the training corpus\n",
    "        self.vocab_len = X.shape[1]\n",
    "        \n",
    "        #Getting the number of positive and negative reviews based on the label of the training set.\n",
    "       \n",
    "        #Positive reviews\n",
    "        self.num_positive_reviews = np.count_nonzero(Y == 1)\n",
    "        #Negative reviews\n",
    "        self.num_negative_reviews = np.count_nonzero(Y == -1)\n",
    "\n",
    "        #Getting the total number of reviews in the training data set.\n",
    "        self.total_number_of_reviews = X.shape[0]\n",
    "\n",
    "        #Count number of word occurences in the corpus for positive and negative reviews and create a dictionnay\n",
    "        #from it.\n",
    "        for review in range(self.total_number_of_reviews):\n",
    "            for word, occurences in zip(X[review].indices, X[review].data):\n",
    "                if traindata.Y[review] == 1:\n",
    "                    self.count_positive[word] += occurences\n",
    "                elif traindata.Y[review] == -1:\n",
    "                    self.count_negative[word] += occurences\n",
    "\n",
    "        # Represent the sum of each occurences for each word in class label\n",
    "        self.total_positive_words = sum(self.count_positive.values())\n",
    "        self.total_negative_words = sum(self.count_negative.values())\n",
    "        \n",
    "        # Represent number of unique words in each label\n",
    "        self.total_positive_term = len(self.count_positive.keys())\n",
    "        self.total_negative_term = len(self.count_negative.keys())\n",
    "\n",
    "        # Denominator number for the computation of P(W|C). C is + or -\n",
    "        #self.deno_pos = self.vocab_len * self.ALPHA + self.total_positive_words \n",
    "        #self.deno_neg = self.vocab_len * self.ALPHA + self.total_negative_words \n",
    "        self.deno_pos = self.vocab_len + self.total_positive_words\n",
    "        self.deno_neg = self.vocab_len + self.total_negative_words\n",
    "\n",
    "        # Compute probabilities for each term inside a concept P(W|C) using log in order to avoid\n",
    "        # future underflow\n",
    "        for word in range(self.vocab_len):\n",
    "            self.P_positive[word] = log((self.count_positive[word] + self.ALPHA) / self.deno_pos)\n",
    "        for word in range(self.vocab_len):\n",
    "            self.P_negative[word] = log((self.count_negative[word] + self.ALPHA) / self.deno_pos)        \n",
    "\n",
    "    def LogSum(self, logx, logy):\n",
    "        return logx + logy\n",
    "\n",
    "\n",
    "    # Predict labels for instances X\n",
    "    # Return: Sparse matrix Y with predicted labels (+1 or -1)\n",
    "    def PredictLabel(self, X):\n",
    "        # Naive Bayes Classification\n",
    "        \n",
    "        pred_labels = []\n",
    "        score_word_pos = 1\n",
    "        score_word_neg = 1\n",
    "        number_of_training_reviews = X.shape[0]\n",
    "\n",
    "        for review in range(number_of_training_reviews):\n",
    "\n",
    "            # Compute the probability of each concept P(C) C is equal to + or - \n",
    "            score_word_pos = log(self.num_positive_reviews/ self.total_number_of_reviews)\n",
    "            score_word_neg = log(self.num_negative_reviews/ self.total_number_of_reviews)\n",
    "\n",
    "            # Compute the probability that each review belongs to a specific class label \n",
    "            for word, occurences in zip(X[review].indices, X[review].data):\n",
    "                # For positive class\n",
    "                score_word_pos = self.LogSum(score_word_pos, self.P_positive[word]*occurences)\n",
    "                # For negative class\n",
    "                score_word_neg = self.LogSum(score_word_neg, self.P_negative[word]*occurences)\n",
    "\n",
    "            # Predict the label of the review.\n",
    "            if score_word_pos > score_word_neg: \n",
    "            # Predict positive\n",
    "                pred_labels.append(1.0)\n",
    "            else:\n",
    "            # Predict negative\n",
    "                pred_labels.append(-1.0)\n",
    "\n",
    "        return pred_labels\n",
    "\n",
    "\n",
    "    # Predict the probability of each indexed review in sparse matrix text\n",
    "    # of being positive\n",
    "    # Prints results\n",
    "    def PredictProb(self, test, indexes):\n",
    "\n",
    "        number_positive_reviews = 0\n",
    "        number_negative_reviews = 0\n",
    "        predicted_label = 0\n",
    "        positive_probs = []\n",
    "        precision_recall_points = []\n",
    "        # Compute the number of positives and negatives reviews in the dataset. \n",
    "        for review in indexes:\n",
    "            if test.Y[review] == 1:\n",
    "                number_positive_reviews += 1\n",
    "            if test.Y[review] == -1:\n",
    "                number_negative_reviews += 1\n",
    "\n",
    "        for review in indexes:\n",
    "\n",
    "            # Compute the probability of each concept P(C) C is equal to + or - \n",
    "            predicted_prob_positive = log(number_positive_reviews/ len(indexes))\n",
    "            predicted_prob_negative = log(number_negative_reviews/ len(indexes))\n",
    "\n",
    "            # Compute the probability that each review belongs to a specific class label \n",
    "            for word, occurences in zip(test.X[review].indices, test.X[review].data):\n",
    "\n",
    "                # For positive class\n",
    "                predicted_prob_positive = self.LogSum(predicted_prob_positive, self.P_positive[word]*occurences)\n",
    "\n",
    "                # For negative class\n",
    "                predicted_prob_negative = self.LogSum(predicted_prob_negative, self.P_negative[word]*occurences)\n",
    "            print(predicted_prob_positive, predicted_prob_negative)\n",
    "            #Normalize probabilities\n",
    "            final_predicted_prob_positive = ((1/predicted_prob_positive) / (1/(predicted_prob_positive) + 1/(predicted_prob_negative)))\n",
    "            final_predicted_prob_negative = ((1/predicted_prob_negative) / (1/(predicted_prob_positive) + 1/(predicted_prob_negative)))\n",
    "\n",
    "            positive_probs.append(final_predicted_prob_positive)\n",
    "            if final_predicted_prob_positive > final_predicted_prob_negative:\n",
    "                predicted_label = 1.0\n",
    "            else:\n",
    "                predicted_label = -1.0\n",
    "            print(review, \":\" ,test.Y[review], predicted_label, final_predicted_prob_positive, final_predicted_prob_negative)\n",
    "            #print(test.Y[review], predicted_label, final_predicted_prob_positive, final_predicted_prob_negative, test.X_reviews[review])\n",
    "\n",
    "        #Compute the Precision and Recall based on a threshold\n",
    "        prediction_based_on_threshold = []\n",
    "        for threshold in np.arange(0.49, 0.51, 0.01):\n",
    "            for prob in positive_probs:\n",
    "                if positive_probs[prob] > threshold :\n",
    "                    prediction_based_on_threshold.append(1) \n",
    "                else :\n",
    "                    prediction_based_on_threshold.append(-1) \n",
    "            ev = Eval(prediction_based_on_threshold, test.Y)\n",
    "            ev.ComputeConfusionMatrix()\n",
    "            precision_recall_points.append((ev.Precision(), ev.Recall()))\n",
    "        print(precision_recall_points)\n",
    "    \n",
    "    def FeaturesSelection(self, vocab):\n",
    "        word_neg = defaultdict(float)\n",
    "        word_pos = defaultdict(float)\n",
    "        for word in self.P_positive:\n",
    "            word_neg[vocab.GetWord(word)] = (self.P_negative[word] - self.P_positive[word])# * (self.count_negative[word] + self.count_positive[word]\n",
    "            word_pos[vocab.GetWord(word)] = (self.P_positive[word] - self.P_negative[word])# * (self.count_positive[word] + self.count_negative[word]\n",
    "        word_neg = sorted(word_neg.items(), key=lambda x: x[1], reverse=True)\n",
    "        word_pos = sorted(word_pos.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(\"TOP 20 Negative Words: \\n\", word_neg[:20])\n",
    "        print(\"TOP 20 Positive Words: \\n\", word_pos[:20])\n",
    "\n",
    "    # Evaluate performance on test data \n",
    "    def Eval(self, test):\n",
    "        print(\"Predicting test reviews labels ...\")\n",
    "        Y_pred = self.PredictLabel(test.X)\n",
    "        print(\"Evaluate the NaiveBayes model ...\")\n",
    "        ev = Eval(Y_pred, test.Y)\n",
    "        return ev.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Training Data\n",
      "Reading Test Data\n",
      "Training the model ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading Training Data\")\n",
    "traindata = IMDBdata(\"%s/train\" % \"data/aclImdb\")\n",
    "print(\"Reading Test Data\")\n",
    "testdata  = IMDBdata(\"%s/test\" % \"data/aclImdb\", vocab=traindata.vocab)    \n",
    "nb = NaiveBayes(traindata, float(1.0))\n",
    "#print(\"Computing Parameters\")\n",
    "#print(\"Evaluating\")\n",
    "#print(\"Test Accuracy: \", nb.Eval(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model ...\n",
      "TOP 20 Negative Words: \n",
      " [('/>4/10', 4.043051267834551), ('seagal', 4.034240638152395), ('2/10', 3.891820298110627), ('boll', 3.8815637979434374), ('uwe', 3.8712010109078907), ('*1/2', 3.828641396489095), ('unwatchable.', 3.8066624897703196), ('thunderbirds', 3.737669618283368), ('/>3/10', 3.713572066704309), ('gamera', 3.713572066704309), ('4/10', 3.6506582412937387), ('wayans', 3.610917912644224), ('awful!', 3.555348061489413), ('/>avoid', 3.465735902799727), ('slater', 3.465735902799727), ('tashan', 3.433987204485147), ('segal', 3.433987204485147), ('drivel.', 3.433987204485147), ('kareena', 3.401197381662156), ('aztec', 3.401197381662156)]\n",
      "TOP 20 Positive Words: \n",
      " [('edie', 4.418840607796598), ('gundam', 4.343805421853684), ('antwone', 4.127134385045093), ('/>8/10', 3.8712010109078907), ('yokai', 3.8712010109078907), ('/>7/10', 3.8501476017100593), ('gunga', 3.8501476017100593), ('/>10/10', 3.828641396489095), ('din', 3.8066624897703196), ('gypo', 3.8066624897703196), ('othello', 3.761200115693562), ('7/10.', 3.6375861597263857), ('tsui', 3.583518938456111), ('paulie', 3.569532696481371), ('blandings', 3.555348061489413), ('goldsworthy', 3.49650756146648), ('/>9/10', 3.465735902799727), ('gino', 3.465735902799727), ('kells', 3.465735902799727), ('visconti', 3.433987204485147)]\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(traindata, float(1.0))\n",
    "nb.FeaturesSelection(traindata.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictProb(test, indexes):\n",
    "\n",
    "    number_positive_reviews = 0\n",
    "    number_negative_reviews = 0\n",
    "    predicted_label = 0\n",
    "    positive_probs = []\n",
    "    negative_probs = []\n",
    "    positive_precision_recall_points = []\n",
    "    negative_precision_recall_points = []\n",
    "    # Compute the number of positives and negatives reviews in the dataset. \n",
    "    for review in indexes:\n",
    "        if test.Y[review] == 1:\n",
    "            number_positive_reviews += 1\n",
    "        if test.Y[review] == -1:\n",
    "            number_negative_reviews += 1\n",
    "\n",
    "    for review in indexes:\n",
    "\n",
    "        # Compute the probability of each concept P(C) C is equal to + or - \n",
    "        predicted_prob_positive = log(number_positive_reviews/ len(indexes))\n",
    "        predicted_prob_negative = log(number_negative_reviews/ len(indexes))\n",
    "\n",
    "        # Compute the probability that each review belongs to a specific class label \n",
    "        for word, occurences in zip(test.X[review].indices, test.X[review].data):\n",
    "\n",
    "            # For positive class\n",
    "            predicted_prob_positive = LogSum(predicted_prob_positive, P_positive[word]*occurences)\n",
    "\n",
    "            # For negative class\n",
    "            predicted_prob_negative = LogSum(predicted_prob_negative, P_negative[word]*occurences)\n",
    "        #Normalize probabilities\n",
    "        final_predicted_prob_positive = ((1/predicted_prob_positive) / (1/(predicted_prob_positive) + 1/(predicted_prob_negative)))\n",
    "        final_predicted_prob_negative = ((1/predicted_prob_negative) / (1/(predicted_prob_positive) + 1/(predicted_prob_negative)))\n",
    "\n",
    "        positive_probs.append(final_predicted_prob_positive)\n",
    "        negative_probs.append(final_predicted_prob_negative)\n",
    "        if final_predicted_prob_positive > final_predicted_prob_negative:\n",
    "            predicted_label = 1.0\n",
    "        else:\n",
    "            predicted_label = -1.0\n",
    "        #print(review, \":\" ,test.Y[review], predicted_label, final_predicted_prob_positive, final_predicted_prob_negative)\n",
    "        #print(test.Y[review], predicted_label, final_predicted_prob_positive, final_predicted_prob_negative, test.X_reviews[review])\n",
    "\n",
    "    #Compute the Precision and Recall based on a threshold\n",
    "    for threshold in np.arange(0.49, 0.5099, 0.001):\n",
    "        positive_prediction_based_on_threshold = []\n",
    "        negative_prediction_based_on_threshold = []\n",
    "        for prob in range(len(indexes)):\n",
    "            if positive_probs[prob] > threshold :\n",
    "                positive_prediction_based_on_threshold.append(1) \n",
    "            else :\n",
    "                positive_prediction_based_on_threshold.append(-1)\n",
    "        ev = Eval(positive_prediction_based_on_threshold, test.Y)\n",
    "        ev.ComputeConfusionMatrix()\n",
    "        positive_precision_recall_points.append((ev.Recall(), ev.Precision()))\n",
    "\n",
    "        for prob in range(len(indexes)):\n",
    "            if negative_probs[prob] > threshold :\n",
    "                negative_prediction_based_on_threshold.append(1) \n",
    "            else :\n",
    "                negative_prediction_based_on_threshold.append(-1)\n",
    "        ev = Eval(negative_prediction_based_on_threshold, test.Y)\n",
    "        ev.ComputeConfusionMatrix()\n",
    "        negative_precision_recall_points.append((ev.Recall(), ev.Precision()))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(*zip(*positive_precision_recall_points), *zip(*negative_precision_recall_points))\n",
    "    plt.title('Precision versus Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njEJBRERiFAoiIhKjUBARkRiFgoiIxPw/BUHzblb2XYEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105af7be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PredictProb(testdata, range(0,25000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
